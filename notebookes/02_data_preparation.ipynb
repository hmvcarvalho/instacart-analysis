{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c0cc090",
   "metadata": {},
   "source": [
    "# Data Preparation - Instacart Market Basket Analysis\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook focuses on cleaning and preparing the Instacart datasets for analysis. Based on the findings from our initial data exploration, we will address data quality issues and ensure our datasets are ready for comprehensive analysis.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "**1. Data Quality Assessment**\n",
    "- Handle missing values across all datasets\n",
    "- Remove or flag duplicate records\n",
    "- Validate data consistency and logical constraints\n",
    "\n",
    "**2. Data Cleaning**\n",
    "- Clean inconsistent data formats\n",
    "- Standardize data types where necessary\n",
    "- Address any anomalies identified during exploration\n",
    "\n",
    "**3. Data Integration**\n",
    "- Merge datasets where appropriate for analysis\n",
    "- Create derived variables if needed\n",
    "- Ensure referential integrity between tables\n",
    "\n",
    "**4. Data Validation**\n",
    "- Verify cleaned data meets quality standards\n",
    "- Perform final consistency checks\n",
    "- Document all transformations applied\n",
    "\n",
    "## Expected Outcome\n",
    "\n",
    "Clean, validated datasets ready for in-depth analysis of customer shopping patterns, product preferences, and ordering behaviors.\n",
    "\n",
    "---\n",
    "\n",
    "*Note: All cleaning steps will be documented with clear explanations and rationale for reproducibility.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fb25b642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "63dbb245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data to variables\n",
    "df_instacart_orders = pd.read_csv('../data/raw/instacart_orders.csv', sep=';')\n",
    "df_products = pd.read_csv('../data/raw/products.csv', sep=';')\n",
    "df_order_products = pd.read_csv('../data/raw/order_products.csv', sep=';')\n",
    "df_aisles = pd.read_csv('../data/raw/aisles.csv', sep=';')\n",
    "df_departments = pd.read_csv('../data/raw/departments.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88233868",
   "metadata": {},
   "source": [
    "### DataFrame instacart_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d1657411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_instacart_orders have 15 duplicated lines\n",
      "===========================================\n",
      "        order_id  user_id  order_number  order_dow  order_hour_of_day  \\\n",
      "354993    391768    57671            19          3                  2   \n",
      "371905    391768    57671            19          3                  2   \n",
      "119251    408114    68324             4          3                  2   \n",
      "321100    408114    68324             4          3                  2   \n",
      "394347    467134    63189            21          3                  2   \n",
      "250626    467134    63189            21          3                  2   \n",
      "145574    794638    50898            24          3                  2   \n",
      "99462     794638    50898            24          3                  2   \n",
      "242618   1021560    53767             3          3                  2   \n",
      "311713   1021560    53767             3          3                  2   \n",
      "273805   1112182   202304            84          3                  2   \n",
      "164581   1112182   202304            84          3                  2   \n",
      "314427   1286742   183220            48          3                  2   \n",
      "411408   1286742   183220            48          3                  2   \n",
      "200059   1782114   106752             1          3                  2   \n",
      "266232   1782114   106752             1          3                  2   \n",
      "230807   1918001   188546            14          3                  2   \n",
      "30371    1918001   188546            14          3                  2   \n",
      "323900   1919531   191501            32          3                  2   \n",
      "257934   1919531   191501            32          3                  2   \n",
      "204042   2125197    14050            48          3                  2   \n",
      "441599   2125197    14050            48          3                  2   \n",
      "223105   2160484   107525            16          3                  2   \n",
      "215294   2160484   107525            16          3                  2   \n",
      "324868   2232988    82565             1          3                  2   \n",
      "345917   2232988    82565             1          3                  2   \n",
      "415163   2282673    86751            49          3                  2   \n",
      "259636   2282673    86751            49          3                  2   \n",
      "142258   2845099    31189            11          3                  2   \n",
      "284038   2845099    31189            11          3                  2   \n",
      "\n",
      "        days_since_prior_order  \n",
      "354993                    10.0  \n",
      "371905                    10.0  \n",
      "119251                    18.0  \n",
      "321100                    18.0  \n",
      "394347                     2.0  \n",
      "250626                     2.0  \n",
      "145574                     2.0  \n",
      "99462                      2.0  \n",
      "242618                     9.0  \n",
      "311713                     9.0  \n",
      "273805                     6.0  \n",
      "164581                     6.0  \n",
      "314427                     4.0  \n",
      "411408                     4.0  \n",
      "200059                     NaN  \n",
      "266232                     NaN  \n",
      "230807                    16.0  \n",
      "30371                     16.0  \n",
      "323900                     7.0  \n",
      "257934                     7.0  \n",
      "204042                     3.0  \n",
      "441599                     3.0  \n",
      "223105                    30.0  \n",
      "215294                    30.0  \n",
      "324868                     NaN  \n",
      "345917                     NaN  \n",
      "415163                     2.0  \n",
      "259636                     2.0  \n",
      "142258                     7.0  \n",
      "284038                     7.0  \n"
     ]
    }
   ],
   "source": [
    "#count duplicated orders\n",
    "dup_num = df_instacart_orders.duplicated().sum()\n",
    "message = f\"df_instacart_orders have {dup_num} duplicated lines\"\n",
    "print(message)\n",
    "\n",
    "print(\"===========================================\")\n",
    "#printing duplicated rows sorted by order_id\n",
    "dup_rows = df_instacart_orders[df_instacart_orders.duplicated(keep=False)]\n",
    "print(dup_rows.sort_values(by='order_id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfc2910",
   "metadata": {},
   "source": [
    "#### DataFrame instacart_orders Analysis\n",
    "- 15 duplicated orders\n",
    "- All happened on Wednesday (order_dow == 3) at 2am (order_hour_of_day == 2)\n",
    "\n",
    "#### Identified Issues\n",
    "1. Lines are matching several fields (order_id, user_id, order_number)\n",
    "2. The same user_id cannot place the same order_id multiple times\n",
    "3. order_id must be a unique key value (not repeated)\n",
    "\n",
    "#### Conclusion\n",
    "We can conclude this probably happened due to a server failure or an error during backup, so we must remove the duplicated lines. Despite representing a residual number of lines, we must keep data integrity in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2ee1ae43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_instacart_orders_cleared have 0 duplicated lines\n",
      "df_instacart_orders_cleared have 0 duplicated order_id\n"
     ]
    }
   ],
   "source": [
    "#removing duplicates and reset index\n",
    "df_instacart_orders_clean = df_instacart_orders.drop_duplicates().reset_index(drop = True)\n",
    "\n",
    "#count duplicated orders\n",
    "dup_num = df_instacart_orders_clean.duplicated().sum()\n",
    "message = f\"df_instacart_orders_cleared have {dup_num} duplicated lines\"\n",
    "print(message)\n",
    "\n",
    "#checking duplicated order_id\n",
    "dup_order_id = df_instacart_orders_clean['order_id'].duplicated().sum()\n",
    "message = f\"df_instacart_orders_cleared have {dup_order_id} duplicated order_id\"\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77494ef",
   "metadata": {},
   "source": [
    "### DataFrame products\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b3730346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "products dataframe have 0 duplicated lines\n",
      "product_id column have 0 duplicated values\n",
      "product_name column have 1361 duplicated values\n",
      "       product_id product_name  aisle_id  department_id\n",
      "37             38          NaN       100             21\n",
      "71             72          NaN       100             21\n",
      "109           110          NaN       100             21\n",
      "296           297          NaN       100             21\n",
      "416           417          NaN       100             21\n",
      "...           ...          ...       ...            ...\n",
      "49552       49553          NaN       100             21\n",
      "49574       49575          NaN       100             21\n",
      "49640       49641          NaN       100             21\n",
      "49663       49664          NaN       100             21\n",
      "49668       49669          NaN       100             21\n",
      "\n",
      "[1258 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# change product_name to lowercase\n",
    "df_products['product_name'] = df_products['product_name'].str.lower()\n",
    "\n",
    "# verify duplicated lines\n",
    "products_dup_lines = df_products.duplicated().sum()\n",
    "message = f\"products dataframe have {products_dup_lines} duplicated lines\"\n",
    "print(message)\n",
    "\n",
    "# verify duplicated values in column produt_id\n",
    "product_id_dup = df_products['product_id'].duplicated().sum()\n",
    "message = f\"product_id column have {product_id_dup} duplicated values\"\n",
    "print(message)\n",
    "\n",
    "# verify duplicated in product_names\n",
    "product_name_dups = df_products['product_name'].duplicated().sum()\n",
    "message = f\"product_name column have {product_name_dups} duplicated values\"\n",
    "print(message)\n",
    "\n",
    "print(df_products[df_products['product_name'].isna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c47608",
   "metadata": {},
   "source": [
    "#### DataFrame products Analysis\n",
    "- 0 duplicated full lines (good data quality)\n",
    "- 0 duplicated product_id, good as each product has unique identifier\n",
    "- 1 361 duplicated values in column \"product_name\" due to NaN values\n",
    "\n",
    "#### Identified Issues\n",
    "**Missing Product Names**:\n",
    "   - These all belong to aisle_id = 100 and department_id = 21\n",
    "   - This suggests a systematic data collection issue for products in this specific category\n",
    "   - Likely represents \"missing\" or \"unknown\" products in the system\n",
    "\n",
    "\n",
    "\n",
    "#### Conclusion\n",
    "We can conclude this missing values are related to a especific Aisle (100) /Department(21) so is better to investigate what they represent in the businness. The collection of this especific data must be reviewd. For further analisys the NaN values should be replaced by \"Unknown Product\" or similar placeholder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "95e2fae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       product_id     product_name  aisle_id  department_id\n",
      "71             72  unknown product       100             21\n",
      "109           110  unknown product       100             21\n",
      "296           297  unknown product       100             21\n",
      "416           417  unknown product       100             21\n",
      "436           437  unknown product       100             21\n",
      "...           ...              ...       ...            ...\n",
      "49552       49553  unknown product       100             21\n",
      "49574       49575  unknown product       100             21\n",
      "49640       49641  unknown product       100             21\n",
      "49663       49664  unknown product       100             21\n",
      "49668       49669  unknown product       100             21\n",
      "\n",
      "[1257 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# replacing the NaN values\n",
    "df_products_clean = df_products[df_products['product_name'].duplicated() == True].fillna('unknown product')\n",
    "\n",
    "#confirm change\n",
    "print(df_products_clean[df_products_clean['product_name'] == 'unknown product'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7b818e",
   "metadata": {},
   "source": [
    "### DataFrame departments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "89f2ad24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "departments dataframe have 0 duplicated lines\n",
      "departments dataframe have 0 duplicated ids\n"
     ]
    }
   ],
   "source": [
    "# verify duplicated lines\n",
    "departments_dup_lines = df_departments.duplicated().sum()\n",
    "message = f\"departments dataframe have {products_dup_lines} duplicated lines\"\n",
    "print(message)\n",
    "\n",
    "# verify duplicated id\n",
    "department_id_dup = df_departments['department_id'].duplicated().sum()\n",
    "message = f\"departments dataframe have {department_id_dup} duplicated ids\"\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17607a9",
   "metadata": {},
   "source": [
    "#### DataFrame department Analysis\n",
    "- 0 duplicated full lines (good data quality)\n",
    "- 0 duplicated product_id, good as each department has unique identifier\n",
    "\n",
    "#### Identified Issues\n",
    "**No issues identified**\n",
    "\n",
    "#### Conclusion\n",
    "We can conclude the department list have quality data, but we can also see the problem discovred before with department 21 is the last line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733e70bb",
   "metadata": {},
   "source": [
    "### DataFrame aisles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b6e5d23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aisles dataframe have 0 duplicated lines\n",
      "aisles dataframe have 0 duplicated ids\n"
     ]
    }
   ],
   "source": [
    "# verify duplicated lines\n",
    "aisles_dup_lines = df_aisles.duplicated().sum()\n",
    "message = f\"aisles dataframe have {aisles_dup_lines} duplicated lines\"\n",
    "print(message)\n",
    "\n",
    "# verify duplicated id\n",
    "aisles_id_dup = df_aisles['aisle_id'].duplicated().sum()\n",
    "message = f\"aisles dataframe have {aisles_id_dup} duplicated ids\"\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd928145",
   "metadata": {},
   "source": [
    "#### DataFrame aisles Analysis\n",
    "- 0 duplicated full lines (good data quality)\n",
    "- 0 duplicated aisle_id, good as each aisle has unique identifier\n",
    "\n",
    "#### Identified Issues\n",
    "**No issues identified**\n",
    "\n",
    "#### Conclusion\n",
    "We can conclude the aisles list have quality data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9d58a3",
   "metadata": {},
   "source": [
    "### DataFrame order_products\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ff68baf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_products dataframe have 0 duplicated lines\n",
      "The smallest order have 1.0 product(s) and the largest have 64.0 prduct(s)\n",
      "orders with NaN values have a max of 64.0 lines\n"
     ]
    }
   ],
   "source": [
    "# verify duplicated lines\n",
    "order_prod_dup_lines = df_order_products.duplicated().sum()\n",
    "message = f\"order_products dataframe have {order_prod_dup_lines} duplicated lines\"\n",
    "print(message)\n",
    "\n",
    "# min and max values for 'add_to_cart_order'\n",
    "min_orders = df_order_products['add_to_cart_order'].min()\n",
    "max_orders = df_order_products['add_to_cart_order'].max()\n",
    "message = f\"The smallest order have {min_orders} product(s) and the largest have {max_orders} prduct(s)\"\n",
    "print(message)\n",
    "\n",
    "# saving lines with NaN in 'add_to_cart_order'\n",
    "missing_values = df_order_products[df_order_products['add_to_cart_order'].isna() == True]\n",
    "#print(missing_values.sort_values(by='order_id'))\n",
    "\n",
    "# using one of the order_id as example to check max add_to_cart_order\n",
    "filtred_df = df_order_products[df_order_products['order_id'] == 61355].sort_values(by='add_to_cart_order')\n",
    "max_add_to_cart = filtred_df['add_to_cart_order'].max()\n",
    "print(f'orders with NaN values have a max of {max_add_to_cart} lines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c5902e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orders with NaN values grouped by order_id:\n",
      "          nan_count\n",
      "order_id           \n",
      "9310              1\n",
      "61355            63\n",
      "102236           31\n",
      "129627            5\n",
      "165801            6\n",
      "171934           40\n",
      "180546            2\n",
      "264710           27\n",
      "293169           13\n",
      "388234            6\n"
     ]
    }
   ],
   "source": [
    "# group by order_id the lines with NaN values\n",
    "nan_grouped = missing_values.groupby('order_id').agg({\n",
    "    'product_id': 'count',  # Count how many products per order have NaN\n",
    "}).rename(columns={'product_id': 'nan_count'})\n",
    "\n",
    "print(\"Orders with NaN values grouped by order_id:\")\n",
    "print(nan_grouped.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4c433219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id\n",
       "4          13\n",
       "9          15\n",
       "11          5\n",
       "19          3\n",
       "20          8\n",
       "           ..\n",
       "3421034    17\n",
       "3421053     9\n",
       "3421071     5\n",
       "3421077     4\n",
       "3421079     1\n",
       "Name: product_id, Length: 450046, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count 'prouct_id' number per order\n",
    "df_order_products.groupby('order_id')['product_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f1e4f269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# count 'prouct_id' number per order\n",
    "grouped = df_order_products.groupby('order_id')['product_id'].count()\n",
    "print(grouped.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae12ebf",
   "metadata": {},
   "source": [
    "#### DataFrame order_products Analysis\n",
    "- 0 duplicated full lines, meaning no errors when saving the data\n",
    "- orders vary bettween 1 and 64 products\n",
    "- orders with more then 64 products have NaN values in column 'add_to_cart_order'\n",
    "\n",
    "\n",
    "#### Identified Issues\n",
    "- feeding issue for order_id with more than 64 products, resulting in NaN values in add_to_cart_order column.\n",
    "\n",
    "#### Conclusion\n",
    "Dataframe have no duplicated lines which pass a firsts impression that all is good, but analyzing deeper we could realize a issue with orders with more than 64 products.This limit suggests a technical constraint in the cart system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cdaf2471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing 'reorder' to type bool\n",
    "df_order_products['reordered'] = df_order_products['reordered'].astype('bool')\n",
    "\n",
    "# replacing NaN values in add_to_cart_order to 999\n",
    "df_order_products_clean = df_order_products[df_order_products['add_to_cart_order'].isna() == True].fillna('999')\n",
    "\n",
    "# changing 'add_to_cart_order' to type int\n",
    "df_order_products_clean['add_to_cart_order'] = df_order_products_clean['add_to_cart_order'].astype('int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "38e32e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVING CLEANED DATASETS FOR ANALYSIS\n",
    "df_instacart_orders_clean.to_csv('../data/data_clean/instacart_orders_clean.csv', index=False)\n",
    "df_products_clean.to_csv('../data/data_clean/products_clean.csv', index=False)\n",
    "df_order_products_clean.to_csv('../data/data_clean/order_products_clean.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
