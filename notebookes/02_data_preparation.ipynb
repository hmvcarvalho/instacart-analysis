{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c0cc090",
   "metadata": {},
   "source": [
    "# Data Preparation - Instacart Market Basket Analysis\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook focuses on cleaning and preparing the Instacart datasets for analysis. Based on the findings from our initial data exploration, we will address data quality issues and ensure our datasets are ready for comprehensive analysis.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "**1. Data Quality Assessment**\n",
    "- Handle missing values across all datasets\n",
    "- Remove or flag duplicate records\n",
    "- Validate data consistency and logical constraints\n",
    "\n",
    "**2. Data Cleaning**\n",
    "- Clean inconsistent data formats\n",
    "- Standardize data types where necessary\n",
    "- Address any anomalies identified during exploration\n",
    "\n",
    "**3. Data Integration**\n",
    "- Merge datasets where appropriate for analysis\n",
    "- Create derived variables if needed\n",
    "- Ensure referential integrity between tables\n",
    "\n",
    "**4. Data Validation**\n",
    "- Verify cleaned data meets quality standards\n",
    "- Perform final consistency checks\n",
    "- Document all transformations applied\n",
    "\n",
    "## Expected Outcome\n",
    "\n",
    "Clean, validated datasets ready for in-depth analysis of customer shopping patterns, product preferences, and ordering behaviors.\n",
    "\n",
    "---\n",
    "\n",
    "*Note: All cleaning steps will be documented with clear explanations and rationale for reproducibility.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb25b642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63dbb245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data to variables\n",
    "df_instacart_orders = pd.read_csv('../data/raw/instacart_orders.csv', sep=';')\n",
    "df_products = pd.read_csv('../data/raw/products.csv', sep=';')\n",
    "df_order_products = pd.read_csv('../data/raw/order_products.csv', sep=';')\n",
    "df_aisles = pd.read_csv('../data/raw/aisles.csv', sep=';')\n",
    "df_departments = pd.read_csv('../data/raw/departments.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88233868",
   "metadata": {},
   "source": [
    "### DataFrame instacart_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1657411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count duplicated orders\n",
    "dup_num = df_instacart_orders.duplicated().sum()\n",
    "message = f\"df_instacart_orders have {dup_num} duplicated lines\"\n",
    "print(message)\n",
    "\n",
    "print(\"===========================================\")\n",
    "#printing duplicated rows sorted by order_id\n",
    "dup_rows = df_instacart_orders[df_instacart_orders.duplicated(keep=False)]\n",
    "print(dup_rows.sort_values(by='order_id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfc2910",
   "metadata": {},
   "source": [
    "#### Duplicated Values Analysis\n",
    "- 15 duplicated orders\n",
    "- All happened on Wednesday (order_dow == 3) at 2am (order_hour_of_day == 2)\n",
    "\n",
    "#### Identified Issues\n",
    "1. Lines are matching several fields (order_id, user_id, order_number)\n",
    "2. The same user_id cannot place the same order_id multiple times\n",
    "3. order_id must be a unique key value (not repeated)\n",
    "\n",
    "#### Conclusion\n",
    "We can conclude this probably happened due to a server failure or an error during backup, so we must remove the duplicated lines. Despite representing a residual number of lines, we must keep data integrity in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2ee1ae43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_instacart_orders_cleared have 0 duplicated lines\n",
      "df_instacart_orders_cleared have 0 duplicated order_id\n"
     ]
    }
   ],
   "source": [
    "#removing duplicates and reset index\n",
    "df_instacart_orders_cleared = df_instacart_orders.drop_duplicates().reset_index(drop = True)\n",
    "\n",
    "#count duplicated orders\n",
    "dup_num = df_instacart_orders_cleared.duplicated().sum()\n",
    "message = f\"df_instacart_orders_cleared have {dup_num} duplicated lines\"\n",
    "print(message)\n",
    "\n",
    "#checking duplicated order_id\n",
    "dup_order_id = df_instacart_orders_cleared['order_id'].duplicated().sum()\n",
    "message = f\"df_instacart_orders_cleared have {dup_order_id} duplicated order_id\"\n",
    "print(message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
